{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0383ac86",
   "metadata": {},
   "source": [
    "My Linkedin : https://www.linkedin.com/in/yasir-ech-chammakhy/\n",
    "\n",
    "My Github : https://github.com/yasirech-chammakhy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c61b74",
   "metadata": {},
   "source": [
    "# Scraping Goldhahn&Sampson Store\n",
    "\n",
    "This notebook contains the source code used to scrape data from the Goldhahn&Sampson Store website. In addition to the code used in the previous notebook, I also concatenated the code from another notebook to collect additional data that wasn't available in the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f35f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7263eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_goldhahnundsampson(url):\n",
    "    driver = webdriver.Chrome('C:\\chromedriver\\chromedriver')\n",
    "    driver.get(url)\n",
    "    src = driver.page_source \n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    url = soup.find_all('h2', {'class': \"caption category_name\"})\n",
    "    hrefs = []\n",
    "    for h2 in url:\n",
    "        a_tag = h2.find('a')\n",
    "        if a_tag:\n",
    "            hrefs.append(a_tag['href'])\n",
    "\n",
    "    PROD_LINK = []\n",
    "    PROD_NAME = []\n",
    "    PROD_PRICE = []\n",
    "    PROD_CATEGORY = []\n",
    "    PROD_IMAGE_URL = []\n",
    "\n",
    "    for link in hrefs : \n",
    "        page_num = 1\n",
    "        while True:\n",
    "            # Visit the current page\n",
    "            page_url = f\"{link}?page={page_num}\"\n",
    "            driver.get(page_url)\n",
    "            src = driver.page_source\n",
    "            soup = BeautifulSoup(src, 'lxml')\n",
    "\n",
    "            # Find all the product wraps\n",
    "            product_wraps = soup.find_all('div', class_='product_wrap')\n",
    "            # If there are no more product wraps, break out of the loop\n",
    "            if not product_wraps:\n",
    "                break\n",
    "\n",
    "            # Extract the product url, product name, product price, and if it's in stock\n",
    "            for product_wrap in product_wraps:\n",
    "                product_name = product_wrap.find('h2', class_='product_name')\n",
    "                prod_name = product_name.text\n",
    "                PROD_NAME.append(prod_name) \n",
    "\n",
    "                product_url = product_name.find('a').get('href')\n",
    "                PROD_LINK.append(product_url)\n",
    "\n",
    "                product_name = product_wrap.find('h2', class_='product_name').text\n",
    "\n",
    "                product_price = product_wrap.find('div', class_='product_price').text\n",
    "                PROD_PRICE.append(product_price) \n",
    "\n",
    "                # Find the product category.\n",
    "                product_category = soup.find('li', {'class': 'last'}).text\n",
    "                PROD_CATEGORY.append(product_category)\n",
    "\n",
    "                # Find the product image URL.\n",
    "                product_image_url =  soup.find('a', class_='product_image')\n",
    "                img_src = product_image_url.find('img').get('src')\n",
    "                img_url = 'https://www.goldhahnundsampson.de/shop/' + img_src\n",
    "                PROD_IMAGE_URL.append(img_url)\n",
    "            # Find the link to the next page\n",
    "            pagination = soup.find('div', {'class': 'flr'})\n",
    "            next_link = pagination.find('a', {'title': ' next page '})\n",
    "\n",
    "            # If there is no next page, break out of the loop\n",
    "            if not next_link:\n",
    "                break\n",
    "\n",
    "            # Increment the page number and continue to the next page\n",
    "            page_num += 1\n",
    "\n",
    "    driver.quit()\n",
    "    # Create a DataFrame from the scraped data\n",
    "    df = pd.DataFrame({\n",
    "        'Product_Link': PROD_LINK,\n",
    "        'Product_Name': PROD_NAME,\n",
    "        'Product_Price': PROD_PRICE,\n",
    "        'Product_Category': PROD_CATEGORY,\n",
    "        'Product_Image_URL': PROD_IMAGE_URL\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de1b9d94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADS\\AppData\\Local\\Temp\\ipykernel_10412\\1937609860.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('C:\\chromedriver\\chromedriver')\n"
     ]
    }
   ],
   "source": [
    "# Retrieve product information for each page\n",
    "df1 = scrape_goldhahnundsampson(\"https://www.goldhahnundsampson.de/shop/Cookbooks:::289.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459bde32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADS\\AppData\\Local\\Temp\\ipykernel_10412\\1937609860.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('C:\\chromedriver\\chromedriver')\n"
     ]
    }
   ],
   "source": [
    "df2 = scrape_goldhahnundsampson(\"https://www.goldhahnundsampson.de/shop/Food:::184.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e81f467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADS\\AppData\\Local\\Temp\\ipykernel_10412\\1937609860.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('C:\\chromedriver\\chromedriver')\n"
     ]
    }
   ],
   "source": [
    "df3 = scrape_goldhahnundsampson(\"https://www.goldhahnundsampson.de/shop/Spirits:::287.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "770ebc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the three dataframes into one\n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Add missing information\n",
    "df['STORE_ID'] = 485\n",
    "df['STORE_NAME'] = 'goldhahn & sampson'\n",
    "df['TEAM_MEMBER'] = 'Yasir ECH-CHAMMAKHY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "625fa055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    'Product_Link': 'PROD_LINK',\n",
    "    'Product_Name': 'PROD_NAME',\n",
    "    'Product_Price': 'PROD_PRICE',\n",
    "    'Product_Category': 'PROD_CATEGORY',\n",
    "    'Product_Image_URL': 'PROD_IMAGE_URL'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0411a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      https://www.goldhahnundsampson.de/shop/Cookboo...\n",
       "1      https://www.goldhahnundsampson.de/shop/Cookboo...\n",
       "2      https://www.goldhahnundsampson.de/shop/Cookboo...\n",
       "3      https://www.goldhahnundsampson.de/shop/Cookboo...\n",
       "4      https://www.goldhahnundsampson.de/shop/Cookboo...\n",
       "                             ...                        \n",
       "730    https://www.goldhahnundsampson.de/shop/Spirits...\n",
       "731    https://www.goldhahnundsampson.de/shop/Spirits...\n",
       "732    https://www.goldhahnundsampson.de/shop/Spirits...\n",
       "733    https://www.goldhahnundsampson.de/shop/Spirits...\n",
       "734    https://www.goldhahnundsampson.de/shop/Spirits...\n",
       "Name: PROD_LINK, Length: 735, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PROD_LINK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4bec3",
   "metadata": {},
   "source": [
    "## Scraping description, brand and id product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the display option to show the full text of the 'PROD_LINK' column\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b16e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\"])\n",
    "df = df[~df[\"PROD_LINK\"].str.startswith(\"https://www.goldhahnundsampson.de/shop/Cookbooks/\")]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd89f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store the scraped data.\n",
    "brands = []\n",
    "descriptions = []\n",
    "ids = []\n",
    "\n",
    "# Loop through the product links in the DataFrame.\n",
    "for link in df['PROD_LINK']:\n",
    "    \n",
    "    soup = BeautifulSoup(requests.get(link).content, 'lxml')\n",
    "\n",
    "    brand = soup.find_all('a', class_='manufacturers_link')\n",
    "    if brand:\n",
    "        brand = brand[0].text.strip()\n",
    "    else:\n",
    "        brand=''\n",
    "\n",
    "    product_description = soup.find_all('div', id='product_description')\n",
    "    if product_description:\n",
    "        product_description = product_description[0].text.strip()\n",
    "    else:\n",
    "        product_description = ''\n",
    "\n",
    "    ean_element = soup.find('div', string='EAN:')\n",
    "    if ean_element:\n",
    "        ean_element = ean_element.find_next('div', {'class': 'value'})\n",
    "        ean = ean_element.text.strip()\n",
    "    else:\n",
    "        ean = ''\n",
    "\n",
    "    # Add the scraped data to the respective lists.\n",
    "    brands.append(brand)\n",
    "    descriptions.append(product_description)\n",
    "    ids.append(ean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8044e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the scraped data to the DataFrame.\n",
    "df['PROD_BRAND'] = brands\n",
    "df['PROD_DESCRIPTION'] = descriptions\n",
    "df[\"PROD_ID\"] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac44289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"store_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eaa365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eed203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
